{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ Join the GLTCH Hive\n",
    "\n",
    "**Contribute your GPU to train AI together!**\n",
    "\n",
    "This notebook connects to the GLTCH distributed training network. Your GPU will help train open-source language models alongside other contributors.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. **Runtime â†’ Change runtime type â†’ T4 GPU** (or better)\n",
    "2. **Run all cells** (Ctrl+F9 or Runtime â†’ Run all)\n",
    "3. Watch your GPU contribute to training! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch websockets requests -q\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ® GPU detected: {gpu_name}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected. Go to Runtime â†’ Change runtime type â†’ T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Peer Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/cyberdreadx/gltch-llm/main/hive/peer.py -O peer.py\n",
    "print(\"âœ… Peer script downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configuration\n",
    "\n",
    "Customize your peer settings below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION - Customize these settings!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Your peer's display name (shown on dashboard)\n",
    "PEER_NAME = \"colab-contributor\"\n",
    "\n",
    "# Model size: '1m' (fastest), '2.7m', '10m', '25m', '50m' (largest)\n",
    "MODEL_SIZE = \"10m\"\n",
    "\n",
    "# Server connection (default public hive)\n",
    "SERVER_URL = \"ws://76.13.121.10:8765\"\n",
    "AUTH_KEY = \"PUBLIC_KEY\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(f\"ğŸ“‹ Configuration:\")\n",
    "print(f\"   Name: {PEER_NAME}\")\n",
    "print(f\"   Model: GLTCH-{MODEL_SIZE.upper()}\")\n",
    "print(f\"   Server: {SERVER_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Join the Hive! ğŸ\n",
    "\n",
    "Run this cell to start training. Your GPU will:\n",
    "- Connect to the coordinator\n",
    "- Download training data\n",
    "- Train and share gradients with other peers\n",
    "\n",
    "**Watch the live dashboard:** http://76.13.121.10:8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python peer.py --server {SERVER_URL} --key {AUTH_KEY} --name {PEER_NAME} --size {MODEL_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Training Stats\n",
    "\n",
    "| Model Size | Parameters | VRAM | Speed |\n",
    "|------------|------------|------|-------|\n",
    "| 1m | ~1M | <1GB | Very Fast |\n",
    "| 2.7m | 2.7M | ~1GB | Fast |\n",
    "| 10m | ~10M | ~2GB | Normal |\n",
    "| 25m | ~25M | ~4GB | Slow |\n",
    "| 50m | ~50M | ~8GB | Slowest |\n",
    "\n",
    "For Colab's free T4 (16GB), we recommend `10m` or `25m`.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Links\n",
    "\n",
    "- **Dashboard:** http://76.13.121.10:8080\n",
    "- **GitHub:** https://github.com/cyberdreadx/gltch-llm\n",
    "- **Created by:** cyberdreadx"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "GLTCH Hive Peer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
